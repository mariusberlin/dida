{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/karolzak/keras-unet/blob/master/keras_unet/models/custom_unet.py\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    SpatialDropout2D,\n",
    "    UpSampling2D,\n",
    "    Input,\n",
    "    concatenate,\n",
    "    multiply,\n",
    "    add,\n",
    "    Activation)\n",
    "\n",
    "\n",
    "def upsample_conv(filters, kernel_size, strides, padding):\n",
    "    return Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n",
    "\n",
    "\n",
    "def upsample_simple(filters, kernel_size, strides, padding):\n",
    "    return UpSampling2D(strides)\n",
    "\n",
    "\n",
    "def attention_gate(inp_1, inp_2, n_intermediate_filters):\n",
    "    \"\"\"Attention gate. Compresses both inputs to n_intermediate_filters filters before processing.\n",
    "       Implemented as proposed by Oktay et al. in their Attention U-net, see: https://arxiv.org/abs/1804.03999.\n",
    "    \"\"\"\n",
    "    inp_1_conv = Conv2D(\n",
    "        n_intermediate_filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(inp_1)\n",
    "    inp_2_conv = Conv2D(\n",
    "        n_intermediate_filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(inp_2)\n",
    "\n",
    "    f = Activation(\"relu\")(add([inp_1_conv, inp_2_conv]))\n",
    "    g = Conv2D(\n",
    "        filters=1,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(f)\n",
    "    h = Activation(\"sigmoid\")(g)\n",
    "    return multiply([inp_1, h])\n",
    "\n",
    "\n",
    "def attention_concat(conv_below, skip_connection):\n",
    "    \"\"\"Performs concatenation of upsampled conv_below with attention gated version of skip-connection\n",
    "    \"\"\"\n",
    "    below_filters = conv_below.get_shape().as_list()[-1]\n",
    "    attention_across = attention_gate(skip_connection, conv_below, below_filters)\n",
    "    return concatenate([conv_below, attention_across])\n",
    "\n",
    "\n",
    "def conv2d_block(\n",
    "    inputs,\n",
    "    use_batch_norm=True,\n",
    "    dropout=0.3,\n",
    "    dropout_type=\"spatial\",\n",
    "    filters=16,\n",
    "    kernel_size=(3, 3),\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    padding=\"same\",\n",
    "):\n",
    "\n",
    "    if dropout_type == \"spatial\":\n",
    "        DO = SpatialDropout2D\n",
    "    elif dropout_type == \"standard\":\n",
    "        DO = Dropout\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"dropout_type must be one of ['spatial', 'standard'], got {dropout_type}\"\n",
    "        )\n",
    "\n",
    "    c = Conv2D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        activation=activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        padding=padding,\n",
    "        use_bias=not use_batch_norm,\n",
    "    )(inputs)\n",
    "    if use_batch_norm:\n",
    "        c = BatchNormalization()(c)\n",
    "    if dropout > 0.0:\n",
    "        c = DO(dropout)(c)\n",
    "    c = Conv2D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        activation=activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        padding=padding,\n",
    "        use_bias=not use_batch_norm,\n",
    "    )(c)\n",
    "    if use_batch_norm:\n",
    "        c = BatchNormalization()(c)\n",
    "    return c\n",
    "\n",
    "\n",
    "def unet_costum(\n",
    "    input_shape,\n",
    "    num_classes=1,\n",
    "    activation=\"relu\",\n",
    "    use_batch_norm=True,\n",
    "    upsample_mode=\"deconv\",  # 'deconv' or 'simple'\n",
    "    dropout=0.3,\n",
    "    dropout_change_per_layer=0.0,\n",
    "    dropout_type=\"spatial\",\n",
    "    use_dropout_on_upsampling=False,\n",
    "    use_attention=False,\n",
    "    filters=16,\n",
    "    num_layers=4,\n",
    "    output_activation=\"sigmoid\",\n",
    "):  # 'sigmoid' or 'softmax'\n",
    "\n",
    "    \"\"\"\n",
    "    Customisable UNet architecture (Ronneberger et al. 2015 [1]).\n",
    "    Arguments:\n",
    "    input_shape: 3D Tensor of shape (x, y, num_channels)\n",
    "    num_classes (int): Unique classes in the output mask. Should be set to 1 for binary segmentation\n",
    "    activation (str): A keras.activations.Activation to use. ReLu by default.\n",
    "    use_batch_norm (bool): Whether to use Batch Normalisation across the channel axis between convolutional layers\n",
    "    upsample_mode (one of \"deconv\" or \"simple\"): Whether to use transposed convolutions or simple upsampling in the decoder part\n",
    "    dropout (float between 0. and 1.): Amount of dropout after the initial convolutional block. Set to 0. to turn Dropout off\n",
    "    dropout_change_per_layer (float between 0. and 1.): Factor to add to the Dropout after each convolutional block\n",
    "    dropout_type (one of \"spatial\" or \"standard\"): Type of Dropout to apply. Spatial is recommended for CNNs [2]\n",
    "    use_dropout_on_upsampling (bool): Whether to use dropout in the decoder part of the network\n",
    "    use_attention (bool): Whether to use an attention dynamic when concatenating with the skip-connection, implemented as proposed by Oktay et al. [3]\n",
    "    filters (int): Convolutional filters in the initial convolutional block. Will be doubled every block\n",
    "    num_layers (int): Number of total layers in the encoder not including the bottleneck layer\n",
    "    output_activation (str): A keras.activations.Activation to use. Sigmoid by default for binary segmentation\n",
    "    Returns:\n",
    "    model (keras.models.Model): The built U-Net\n",
    "    Raises:\n",
    "    ValueError: If dropout_type is not one of \"spatial\" or \"standard\"\n",
    "    [1]: https://arxiv.org/abs/1505.04597\n",
    "    [2]: https://arxiv.org/pdf/1411.4280.pdf\n",
    "    [3]: https://arxiv.org/abs/1804.03999\n",
    "    \"\"\"\n",
    "\n",
    "    if upsample_mode == \"deconv\":\n",
    "        upsample = upsample_conv\n",
    "    else:\n",
    "        upsample = upsample_simple\n",
    "\n",
    "    # Build U-Net model\n",
    "    inputs = Input(input_shape)\n",
    "    x = inputs\n",
    "   \n",
    "    down_layers = []\n",
    "    for l in range(num_layers):\n",
    "        x = conv2d_block(\n",
    "            inputs=x,\n",
    "            filters=filters,\n",
    "            use_batch_norm=use_batch_norm,\n",
    "            dropout=dropout,\n",
    "            dropout_type=dropout_type,\n",
    "            activation=activation,\n",
    "        )\n",
    "        down_layers.append(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        dropout += dropout_change_per_layer\n",
    "        filters = filters * 2  # double the number of filters with each layer\n",
    "   \n",
    "    x = conv2d_block(\n",
    "        inputs=x,\n",
    "        filters=filters,\n",
    "        use_batch_norm=use_batch_norm,\n",
    "        dropout=dropout,\n",
    "        dropout_type=dropout_type,\n",
    "        activation=activation,\n",
    "    )\n",
    "\n",
    "    if not use_dropout_on_upsampling:\n",
    "        dropout = 0.0\n",
    "        dropout_change_per_layer = 0.0\n",
    "   \n",
    "    for conv in reversed(down_layers):\n",
    "        filters //= 2  # decreasing number of filters with each layer\n",
    "        dropout -= dropout_change_per_layer\n",
    "        x = upsample(filters, (2, 2), strides=(2, 2), padding=\"same\")(x)\n",
    "        if use_attention:\n",
    "            x = attention_concat(conv_below=x, skip_connection=conv)\n",
    "        else:\n",
    "            x = concatenate([x, conv])\n",
    "        x = conv2d_block(\n",
    "            inputs=x,\n",
    "            filters=filters,\n",
    "            use_batch_norm=use_batch_norm,\n",
    "            dropout=dropout,\n",
    "            dropout_type=dropout_type,\n",
    "            activation=activation,\n",
    "        )\n",
    " \n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=output_activation)(x)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
