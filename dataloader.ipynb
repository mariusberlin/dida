{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%run transforms.ipynb\n",
    "\n",
    "import  PIL\n",
    "from PIL import Image\n",
    "#import gdcm\n",
    "import tensorflow as tf\n",
    "#import pydicom as dicom\n",
    "from pathlib import Path\n",
    "\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from skimage.transform import resize\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import class_weight\n",
    "import scipy\n",
    "import skimage\n",
    "import time\n",
    "from time import perf_counter\n",
    "import datetime\n",
    "import logging\n",
    "import random\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import sys\n",
    "import datetime\n",
    "import imageio\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "### data generator\n",
    "\n",
    "\n",
    "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs_inputs, list_IDs_masks, epochs, batch_size, dim, n_channels,shuffle, num_output_nodes,augmentation,crop_pad):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        #self.list_IDs = list_IDs\n",
    "        self.list_IDs_inputs = list_IDs_inputs\n",
    "        self.list_IDs_masks =  list_IDs_masks\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.num_output_nodes = num_output_nodes\n",
    "        self.augmentation = augmentation\n",
    "        self.crop_pad = crop_pad\n",
    "        self.on_epoch_end()\n",
    "        #to use next\n",
    "        self.n = 0\n",
    "        self.max = self.__len__()\n",
    "        \n",
    "    #to use next\n",
    "    def __next__(self):\n",
    "        if self.n >= self.max:\n",
    "           self.n = 0\n",
    "        result = self.__getitem__(self.n)\n",
    "        self.n += 1\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs_inputs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_inputs = [self.list_IDs_inputs[k] for k in indexes]\n",
    "        list_IDs_masks = [self.list_IDs_masks[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(list_IDs_inputs,list_IDs_masks)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs_inputs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            #print(self.indexes)\n",
    "            \n",
    "    def standardize(self, pixel_array):\n",
    "        #Normilsation\n",
    "        #pixel_array = (pixel_array-np.amin(pixel_array))/(np.amax(pixel_array)-np.amin(pixel_array))\n",
    "        #Standardisation\n",
    "        pixel_array = (pixel_array - np.mean(pixel_array)) / np.std(pixel_array)\n",
    "        return pixel_array\n",
    "    \n",
    "    def normalize(self,pixel_array):\n",
    "        pixel_array = (pixel_array - pixel_array.min())/(pixel_array.max()-pixel_array.min())\n",
    "        return pixel_array\n",
    "            \n",
    "    ###extract all slices from a series based on one slice path\n",
    "    def extract_and_augment(self,image_path,random_seed_aug,case):\n",
    "         \n",
    "               \n",
    "        \n",
    "        #Load data   \n",
    "        pixel_array = imageio.imread(image_path)\n",
    "      \n",
    "    \n",
    "        #augmentation        \n",
    "        rand = random.randrange(0, 100, 1)\n",
    "        if rand < self.augmentation * 100 :\n",
    "            pixel_array = randaugm(pixel_array,random_seed_aug,case)\n",
    "            \n",
    "        \n",
    "        if case == \"mask\":\n",
    "            pixel_array = np.expand_dims(pixel_array,axis = 2)\n",
    "\n",
    "        return pixel_array \n",
    "    \n",
    "    def image_processing(self,ID, standardize, normalize,random_seed_aug, case):\n",
    "        \n",
    "        array = self.extract_and_augment(ID,random_seed_aug,case)\n",
    "        \n",
    "        #standardization\n",
    "        if standardize == True:\n",
    "            array = self.standardize(array)\n",
    "        elif standardize == False:\n",
    "            array = array\n",
    "        \n",
    "        #normalization\n",
    "        if normalize == True:\n",
    "            array = self.normalize(array)\n",
    "        elif normalize == False:\n",
    "            array = array\n",
    "            \n",
    "        \n",
    "        #print (\"Min/Max pixel: \" ,np.amin(array),\"/\" ,np.amax(array))\n",
    "        return array\n",
    "        \n",
    "    \n",
    "    def __data_generation(self, list_IDs_inputs, list_IDs_masks):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "\n",
    "\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        Y = np.empty((self.batch_size,*self.dim[:2],1))\n",
    "        \n",
    "        #for dataugmentation\n",
    "        \n",
    "        list_IDs_all = [(list_IDs_inputs[i], list_IDs_masks[i]) for i in range(0, len(list_IDs_inputs))]\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID_tuple in enumerate(list_IDs_all): \n",
    "             # Store sample\n",
    "             #X[i,] = np.load('data/' + ID + '.npy')\n",
    "            \n",
    "            if self.augmentation > 0:\n",
    "                random_seed_aug = random.randint(1,1000000000)\n",
    "            elif self.augmentation == 0:\n",
    "                random_seed_aug = None\n",
    "                \n",
    "            \n",
    "            X[i] = self.image_processing(ID_tuple[0], False, True,random_seed_aug,\"image\")\n",
    "            Y[i] = self.image_processing(ID_tuple[1], False, False,random_seed_aug,\"mask\")\n",
    "            \n",
    "            Y = np.where(Y > 0.5, 1, 0)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
