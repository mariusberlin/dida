{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples:  25\n",
      "17\n",
      "val_split:  7\n",
      "Samples training set:  17\n",
      "Samples validation set:  7\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.8242 - f1: 0.2707 - jaccard: 0.1568 - val_loss: 0.6953 - val_f1: 0.2339 - val_jaccard: 0.1362\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.7988 - f1: 0.2878 - jaccard: 0.1694 - val_loss: 0.7010 - val_f1: 0.2412 - val_jaccard: 0.1406\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.7748 - f1: 0.3007 - jaccard: 0.1771 - val_loss: 0.7031 - val_f1: 0.2424 - val_jaccard: 0.1412\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.7558 - f1: 0.3146 - jaccard: 0.1874 - val_loss: 0.6999 - val_f1: 0.2467 - val_jaccard: 0.1443\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.7374 - f1: 0.3337 - jaccard: 0.2009 - val_loss: 0.6928 - val_f1: 0.2464 - val_jaccard: 0.1447\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.7230 - f1: 0.3454 - jaccard: 0.2097 - val_loss: 0.6841 - val_f1: 0.2448 - val_jaccard: 0.1444\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.7129 - f1: 0.3481 - jaccard: 0.2091 - val_loss: 0.6740 - val_f1: 0.2400 - val_jaccard: 0.1416\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6933 - f1: 0.3653 - jaccard: 0.2252 - val_loss: 0.6625 - val_f1: 0.2229 - val_jaccard: 0.1308\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6876 - f1: 0.3612 - jaccard: 0.2223 - val_loss: 0.6494 - val_f1: 0.1957 - val_jaccard: 0.1145\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.6544 - f1: 0.4197 - jaccard: 0.2672 - val_loss: 0.6352 - val_f1: 0.1604 - val_jaccard: 0.0942\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6161 - f1: 0.4476 - jaccard: 0.2840 - val_loss: 0.6200 - val_f1: 0.1838 - val_jaccard: 0.1079\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.6062 - f1: 0.4740 - jaccard: 0.3116 - val_loss: 0.6102 - val_f1: 0.3707 - val_jaccard: 0.2291\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.5702 - f1: 0.5124 - jaccard: 0.3438 - val_loss: 0.5846 - val_f1: 0.0730 - val_jaccard: 0.0473\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.5535 - f1: 0.5135 - jaccard: 0.3410 - val_loss: 0.5682 - val_f1: 0.0080 - val_jaccard: 0.0150\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.5332 - f1: 0.5487 - jaccard: 0.3812 - val_loss: 0.5513 - val_f1: 0.0031 - val_jaccard: 0.0127\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.4940 - f1: 0.5929 - jaccard: 0.4200 - val_loss: 0.5347 - val_f1: 0.0223 - val_jaccard: 0.0216\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4775 - f1: 0.6177 - jaccard: 0.4465 - val_loss: 0.5188 - val_f1: 6.0928e-04 - val_jaccard: 0.0115\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4606 - f1: 0.6337 - jaccard: 0.4716 - val_loss: 0.5031 - val_f1: 2.1554e-04 - val_jaccard: 0.0113\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4437 - f1: 0.6623 - jaccard: 0.5082 - val_loss: 0.4886 - val_f1: 1.0780e-04 - val_jaccard: 0.0113\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4189 - f1: 0.6891 - jaccard: 0.5255 - val_loss: 0.4763 - val_f1: 7.1327e-05 - val_jaccard: 0.0113\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4151 - f1: 0.6947 - jaccard: 0.5518 - val_loss: 0.4655 - val_f1: 3.5668e-05 - val_jaccard: 0.0113\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4028 - f1: 0.7158 - jaccard: 0.5671 - val_loss: 0.4569 - val_f1: 0.0021 - val_jaccard: 0.0123\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.3785 - f1: 0.7470 - jaccard: 0.6087 - val_loss: 0.4503 - val_f1: 0.0000e+00 - val_jaccard: 0.0113\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.3716 - f1: 0.7578 - jaccard: 0.6151 - val_loss: 0.4431 - val_f1: 0.0000e+00 - val_jaccard: 0.0113\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3556 - f1: 0.7827 - jaccard: 0.6412 - val_loss: 0.4374 - val_f1: 0.0000e+00 - val_jaccard: 0.0113\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3490 - f1: 0.7893 - jaccard: 0.6547 - val_loss: 0.4334 - val_f1: 0.0000e+00 - val_jaccard: 0.0113\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3428 - f1: 0.7894 - jaccard: 0.6513 - val_loss: 0.4260 - val_f1: 0.0158 - val_jaccard: 0.0194\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.3386 - f1: 0.8004 - jaccard: 0.6680 - val_loss: 0.4268 - val_f1: 0.0000e+00 - val_jaccard: 0.0112\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.3134 - f1: 0.8353 - jaccard: 0.7167 - val_loss: 0.4242 - val_f1: 0.0000e+00 - val_jaccard: 0.0112\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3127 - f1: 0.8323 - jaccard: 0.7095 - val_loss: 0.4208 - val_f1: 2.8531e-04 - val_jaccard: 0.0114\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3103 - f1: 0.8258 - jaccard: 0.7087 - val_loss: 0.4169 - val_f1: 0.0206 - val_jaccard: 0.0220\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3022 - f1: 0.8431 - jaccard: 0.7294 - val_loss: 0.4096 - val_f1: 0.0434 - val_jaccard: 0.0332\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2839 - f1: 0.8587 - jaccard: 0.7498 - val_loss: 0.4087 - val_f1: 0.0397 - val_jaccard: 0.0313\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2851 - f1: 0.8562 - jaccard: 0.7527 - val_loss: 0.4001 - val_f1: 0.0845 - val_jaccard: 0.0530\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2967 - f1: 0.8356 - jaccard: 0.7228 - val_loss: 0.4010 - val_f1: 0.0685 - val_jaccard: 0.0457\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2650 - f1: 0.8795 - jaccard: 0.7841 - val_loss: 0.3872 - val_f1: 0.1653 - val_jaccard: 0.0951\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2646 - f1: 0.8829 - jaccard: 0.7883 - val_loss: 0.3757 - val_f1: 0.2850 - val_jaccard: 0.1636\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2721 - f1: 0.8639 - jaccard: 0.7656 - val_loss: 0.3714 - val_f1: 0.3035 - val_jaccard: 0.1750\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2656 - f1: 0.8766 - jaccard: 0.7799 - val_loss: 0.3686 - val_f1: 0.3373 - val_jaccard: 0.1950\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2685 - f1: 0.8654 - jaccard: 0.7643 - val_loss: 0.3680 - val_f1: 0.4158 - val_jaccard: 0.2488\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2599 - f1: 0.8780 - jaccard: 0.7837 - val_loss: 0.3613 - val_f1: 0.3478 - val_jaccard: 0.2013\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2520 - f1: 0.8902 - jaccard: 0.8013 - val_loss: 0.3614 - val_f1: 0.3449 - val_jaccard: 0.2001\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2536 - f1: 0.8889 - jaccard: 0.7996 - val_loss: 0.3650 - val_f1: 0.3422 - val_jaccard: 0.1966\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2483 - f1: 0.8940 - jaccard: 0.8065 - val_loss: 0.3736 - val_f1: 0.3903 - val_jaccard: 0.2309\n",
      "Epoch 45/100\n",
      "2/5 [===========>..................] - ETA: 7s - loss: 0.2337 - f1: 0.9085 - jaccard: 0.8325 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f07aaa003978>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    167\u001b[0m      \u001b[1;34m'comment'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m\"baseline_more_data\"\u001b[0m \u001b[1;31m#comment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m          }\n\u001b[1;32m--> 169\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-f07aaa003978>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m    138\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_checkpoints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                        )\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager_dataset_or_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m       \u001b[1;31m# Make sure that y, sample_weights, validation_split are not passed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint ,ReduceLROnPlateau, Callback, LearningRateScheduler\n",
    "import sys\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import logging\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%run dictionary.ipynb\n",
    "%run dataloader.ipynb\n",
    "%run metrics.ipynb\n",
    "%run unet_costum.ipynb\n",
    "\n",
    "\n",
    "'''\n",
    "  Segmentation Pulmonary Aorta\n",
    "'''\n",
    "\n",
    "\n",
    "def train(params) :\n",
    "    \n",
    "    \n",
    "    # Allow GPU growth\n",
    "    '''\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "    )\n",
    "    \n",
    "        \n",
    "    \n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "    '''\n",
    "    #strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "    # Open a strategy scope.for using single/multiple GPUs)\n",
    "    #with strategy.scope():\n",
    "        \n",
    "    #Dataset\n",
    "    x_train, y_train, x_val, y_val = data_dict(params['dataset'] + '.csv', params['val_size'], params['random_state'])\n",
    "\n",
    "\n",
    "\n",
    "    #initialize generators \n",
    "    training_generator = DataGenerator(x_train, y_train, params[\"epochs\"], params['batch_size'],\n",
    "                                   params[\"dim\"], params['n_channels'],\n",
    "                                   params[\"shuffle\"],\n",
    "                                   params['num_output_nodes'], params['augmentation'],params['crop_pad'])\n",
    "\n",
    "    validation_generator = DataGenerator(x_val, y_val, params[\"epochs\"],\n",
    "                                         params['batch_size'],\n",
    "                                         params[\"dim\"], params['n_channels'],\n",
    "                                         False, params['num_output_nodes'], False,params['crop_pad'])\n",
    "\n",
    "    #model\n",
    "\n",
    "    model =  unet_costum(input_shape = params['dim'], dropout=params['dropout'], output_activation = \"sigmoid\")\n",
    "\n",
    "\n",
    "    #optimizer\n",
    "    if params[\"optimizer\"] == \"sgd\" :\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=params['learning_rate'],\n",
    "                                            momentum=0.9, nesterov=params['nesterov'], name=\"SGD\")\n",
    "    elif params[\"optimizer\"] == \"adam\" :\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=params['learning_rate'])\n",
    "\n",
    "\n",
    "\n",
    "    #METRICS = [\"accuracy\"]\n",
    "    #METRICS = [f1_sk,jaccard_sk]\n",
    "    METRICS = [f1,jaccard]\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=METRICS)\n",
    "\n",
    "    def lr_step_decay(epoch) :\n",
    "        # https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
    "        drop_rate = 0.5\n",
    "        epochs_drop = 5\n",
    "        return params['learning_rate'] * math.pow(drop_rate, math.floor(epoch / epochs_drop))\n",
    "\n",
    "    def lr_steady(epoch) :\n",
    "        return params['learning_rate']\n",
    "\n",
    "    if params[\"lr_decay\"] == \"plateau\" :\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=2, verbose=1,\n",
    "                                      mode='min', min_delta=0, cooldown=0, min_lr=0)\n",
    "    elif params[\"lr_decay\"] == \"steps\" :\n",
    "        reduce_lr = LearningRateScheduler(lr_step_decay, verbose=1)\n",
    "\n",
    "    elif params[\"lr_decay\"] == False :\n",
    "        reduce_lr = LearningRateScheduler(lr_steady, verbose=1)\n",
    "\n",
    "    else :\n",
    "        print(\"Learning rate decay unknown!\")\n",
    "\n",
    "    class LearningRateLogger(tf.keras.callbacks.Callback) :\n",
    "        def on_epoch_end(self, epoch, logs) :\n",
    "            logs['z_learningrate'] = K.eval(self.model.optimizer.lr)  # replace it with your metrics\n",
    "\n",
    "\n",
    "    # Checkpoints\n",
    "    if params['history'] == True :\n",
    "        my_checkpoints = [\n",
    "            ModelCheckpoint('./models/'+ params['comment'] + \".hdf5\", monitor='val_loss', verbose=1,\n",
    "                            save_best_only=True, mode='min', period=1),\n",
    "            LearningRateLogger(),\n",
    "            tf.keras.callbacks.CSVLogger('./models/' + str(model_name) + '.log', separator=',',\n",
    "                                         append=False),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode=\"min\", patience=5, restore_best_weights=True),\n",
    "            reduce_lr\n",
    "            ]\n",
    "    else :\n",
    "        my_checkpoints = None\n",
    "    \n",
    "    workers = 3\n",
    "\n",
    "    # Train model on dataset\n",
    "    model.fit(x = training_generator,\n",
    "             steps_per_epoch=len(x_train) // params['batch_size'],\n",
    "              validation_data = validation_generator,\n",
    "                  validation_steps=len(x_val) // params['batch_size'],\n",
    "                  epochs=params['epochs'],\n",
    "                  callbacks=my_checkpoints,\n",
    "                    workers=workers\n",
    "                       )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params = {'dim' : (256, 256, 4),  # (depth,length,width)\n",
    "      'batch_size' : 3,\n",
    "      'num_output_nodes' : 1, \n",
    "      'n_channels' : 1,\n",
    "      'epochs' : 100,\n",
    "      'shuffle' : True,\n",
    "      'crop_pad': False,\n",
    "      'learning_rate' : 0.0001,\n",
    "      'optimizer' : \"adam\",\n",
    "      'momentum' : 0,\n",
    "      'lr_decay' : \"plateau\",\n",
    "      'nesterov' : False,\n",
    "      'reg_factor' : 0.001,\n",
    "      'model_type' : \"unet_costum\",\n",
    "      'dropout' : 0,\n",
    "      'history' : False,\n",
    "      'val_size' : 0.3,\n",
    "      'test_size' : 0,\n",
    "      'random_state' : 123,  # identical sample_size required\n",
    "      'dataset' : \"mapping\",\n",
    "      'augmentation' : 0, # float between 0 and 1, define the probablilite of the transf funktion being called\n",
    "     'comment' : \"baseline_more_data\" #comment \n",
    "         }\n",
    "train(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
